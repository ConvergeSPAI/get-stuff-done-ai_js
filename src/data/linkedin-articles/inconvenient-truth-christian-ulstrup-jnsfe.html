 <p>I've been a little hesitant to post this and may end up deleting it, but there's an uncomfortable truth that CEOs need to hear in re AI...</p>

<p>I've seen this technology stoke a sort of status anxiety in particular types of people, many of whom with roles at or near the c-level, and that may be blinding you to the urgent nature of what it implies.</p>

<p>I'm not going to sugar-coat this: a lot of these folks are justifiably anxious (though, with a bit of a mindset shift, they don't necessarily have to be—every single person, regardless of their role, stands to benefit if they cultivate some curiosity, humility, and relentless focus on elevating the customer's good); the indisputable existence of cheap "word-crunching machines" threaten the positions of lawyers, engineers, marketers, financiers, product managers, et al and the various managerial roles at different levels of corporate aggregation.</p>

<p>If you enjoyed being a bottleneck in some critical knowledge work process that involved processing and producing lots of unstructured data and were taking a slice of the capital that flowed through it (whether in management fees, a fat paycheck, or whatever other form) without having to also regularly retool, you are likely to have a very nasty wake up call in the next 2–5 years when that money spigot gets turned off or redirected toward a lean team that moves 10x as fast with 1/10th the overhead and team size and eats your lunch.</p>

<p><strong>Highly regulated industries <em>are not safe</em>. PE portcos with privileged access to capital <em>are not safe</em>. Tech companies per se <em>are not safe</em>.</strong></p>

<p>BUT—your fate is not sealed, and outsized upside is within your grasp...</p>

<p>There is, however, one consistent limiting factor that I've seen that prevents CEOs from really appreciating the magnitude of the challenge and then empowering their employees to overcome it through bottoms-up experimentation (which is absolutely critical in the context of a new general purpose technology, which generate AI is):</p>

<p><strong>Centralized IT.</strong></p>

<p>This is certainly not true of all enterprise IT leaders or organizations—but I have seen it enough that there's a meaningful trend: IT leadership (and, by extension, the various "controllers" across sec, legal, and procurement) may not want to give up power and control of technology vendor purchasing decisions, of implementation and adoption, of in-house development; but, if you want to bring your organization into the 21st century, you will need to wrest it from their hands and give it to the people who are closest to the customer and the problems they face.</p>

<p>Tools like Claude Code are making it possible for frontline workers with direct access to "sticky information" to encode salient information into customer software. This will mean some people build their own home-grown solutions and others will want to purchase this new product category of hyper-specialized niche tooling from external vendors.</p>

<p>If they cannot do this themselves, and FAST, the feedback loop will be too long for the org to learn, and that approval bottleneck will ultimate kill any chance you have of making it to the other side of this transformation.</p>

<p>So, practically, if there were one thing I'd recommend doing to diagnose and start addressing this issue, it would be to measure exactly how long it takes for an employee who wants to use a new piece of tech to apply it to the problem at hand.</p>

<p>If it is more than a day, then you are in the danger zone; I say this knowing that for many orgs, this is days, if not months (in certain parts of the public sector, even years).</p>

<p>Figure out what would have to be true to reduce that cycle time by 10x. And then by another 10x. And so on. Don't be satisfied until you've prudently decentralized IT; there may be kicking and screaming and gnashing of teeth, but you will be better off for it (and, for the folks on those teams who see the AI light along the way, so will they).</p> 